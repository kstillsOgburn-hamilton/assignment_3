/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.5.0) or chardet (4.0.0) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
Seed set to 42
/home/oadenira/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
/home/oadenira/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:215: UserWarning: 
NVIDIA GeForce RTX 5070 Ti with CUDA capability sm_120 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_70 sm_75 sm_80 sm_86 sm_90.
If you want to use the NVIDIA GeForce RTX 5070 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(
You are using a CUDA device ('NVIDIA GeForce RTX 5070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
loading tokenizer...
preparing and initializing the IMBD data module...
training in process...
Traceback (most recent call last):
  File "/home/oadenira/.local/lib/python3.10/site-packages/torchdata/datapipes/iter/util/cacheholder.py", line 38, in _assert_portalocker
    import portalocker  # noqa: F401
ModuleNotFoundError: No module named 'portalocker'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/oadenira/assignment_3/src/train.py", line 84, in <module>
    main()
  File "/home/oadenira/assignment_3/src/train.py", line 78, in main
    trainer.fit(model_module, datamodule=data_module)
  File "/home/oadenira/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/oadenira/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/oadenira/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/oadenira/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 971, in _run
    self._data_connector.prepare_data()
  File "/home/oadenira/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py", line 94, in prepare_data
    call._call_lightning_datamodule_hook(trainer, "prepare_data")
  File "/home/oadenira/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 199, in _call_lightning_datamodule_hook
    return fn(*args, **kwargs)
  File "/home/oadenira/assignment_3/src/datamodule.py", line 26, in prepare_data
    IMDB(root=self.root, split="train") # 25k observations
  File "/home/oadenira/.local/lib/python3.10/site-packages/torchtext/data/datasets_utils.py", line 193, in wrapper
    return fn(root=new_root, *args, **kwargs)
  File "/home/oadenira/.local/lib/python3.10/site-packages/torchtext/data/datasets_utils.py", line 155, in new_fn
    result.append(fn(root, item, **kwargs))
  File "/home/oadenira/.local/lib/python3.10/site-packages/torchtext/datasets/imdb.py", line 95, in IMDB
    cache_compressed_dp = url_dp.on_disk_cache(
  File "/home/oadenira/.local/lib/python3.10/site-packages/torch/utils/data/datapipes/datapipe.py", line 141, in class_function
    result_pipe = cls(source_dp, *args, **kwargs)
  File "/home/oadenira/.local/lib/python3.10/site-packages/torchdata/datapipes/iter/util/cacheholder.py", line 208, in __init__
    _assert_portalocker()
  File "/home/oadenira/.local/lib/python3.10/site-packages/torchdata/datapipes/iter/util/cacheholder.py", line 47, in _assert_portalocker
    raise ModuleNotFoundError(
ModuleNotFoundError: Package `portalocker` is required to be installed to use this datapipe.Please use `pip install 'portalocker>=2.0.0'` or`conda install -c conda-forge 'portalocker>=2/0.0'`to install the package

Seed set to 42
loading tokenizer...
preparing and initializing the IMBD data module...
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
training in process...
/opt/miniforge3/lib/python3.12/site-packages/torch/__init__.py:1551: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
  return _C._get_float32_matmul_precision()
You are using a CUDA device ('NVIDIA GeForce RTX 5070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/opt/miniforge3/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
/opt/miniforge3/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:751: Checkpoint directory /home/dmaurett/assignment_3/src/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/opt/miniforge3/lib/python3.12/site-packages/lightning/pytorch/utilities/model_summary/model_summary.py:231: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.

  | Name             | Type                      | Params | Mode
-----------------------------------------------------------------------
0 | model            | Bi_LSTM                   | 6.3 M  | train
1 | criterion        | NLLLoss                   | 0      | train
2 | train_acc        | MulticlassAccuracy        | 0      | train
3 | val_acc          | MulticlassAccuracy        | 0      | train
4 | test_acc         | MulticlassAccuracy        | 0      | train
5 | test_conf_matrix | MulticlassConfusionMatrix | 0      | train
-----------------------------------------------------------------------
6.3 M     Trainable params
0         Non-trainable params
6.3 M     Total params
25.101    Total estimated model params size (MB)
10        Modules in train mode
0         Modules in eval mode
Epoch 0: 100%|█| 1094/1094 [00:28<00:00, 37.84it/s, v_num=dvng, train_loss_step=0.691, val_loss=0.691
training done!                                                                                       
`Trainer.fit` stopped: `max_epochs=1` reached.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Testing DataLoader 0: 100%|████████████████████████████████████████| 235/235 [00:03<00:00, 66.96it/s]
Traceback (most recent call last):
  File "/home/dmaurett/assignment_3/src/train.py", line 100, in <module>
    main()
  File "/home/dmaurett/assignment_3/src/train.py", line 97, in main
    trainer.test(model_module, datamodule=data_module)
  File "/opt/miniforge3/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 774, in test
    return call._call_and_handle_interrupt(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniforge3/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniforge3/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 816, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniforge3/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/opt/miniforge3/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1048, in _run_stage
    return self._evaluation_loop.run()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniforge3/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniforge3/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 152, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/opt/miniforge3/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 295, in on_run_end
    self._on_evaluation_epoch_end()
  File "/opt/miniforge3/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 375, in _on_evaluation_epoch_end
    call._call_lightning_module_hook(trainer, hook_name)
  File "/opt/miniforge3/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
TypeError: LightningBi_LSTM.on_test_epoch_end() missing 1 required positional argument: 'outputs'
